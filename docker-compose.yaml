version: "3.9"
services:
  nginx-file:
    image: nginx:latest
    volumes:
      - ./gateway/nginx/conf.d:/etc/nginx/conf.d
    ports:
      - 93:93
    networks:
      - file-network
    depends_on:
      - FileServer
      - FileClient
    deploy:
      restart_policy:
        condition: always

  FileClient:
    image: file-client-image
    container_name: file-client-container
    build:
      context: .
      dockerfile: ./frontend/Dockerfile.local
    expose:
      - 3000
    volumes:
      - ./frontend/client/src:/app/src
      # Mount backend at the path tsconfig expects relative to /app (which is frontend/client)
      - ./backend:/backend:ro
    command: npm start
    networks:
      - file-network
    depends_on:
      - FileServer

  FileServer:
    image: file-server-image
    container_name: file-server-container
    build:
      context: ./backend
      dockerfile: ./Dockerfile.local
    expose:
      - 8000
    volumes:
      - ./backend:/app/
    command: bun --watch src/index.ts
    networks:
      - file-network
    depends_on:
      - tika
      - weaviate

  tika:
    image: apache/tika:latest
    container_name: tika-container
    expose:
      - 9998
    networks:
      - file-network
    deploy:
      restart_policy:
        condition: always

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:latest
    container_name: weaviate-container
    expose:
      - 8080
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      ENABLE_MODULES: 'text2vec-openai'
      OPENAI_APIKEY: ${OPENAI_API_KEY}
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
    networks:
      - file-network
    deploy:
      restart_policy:
        condition: always

networks:
  file-network:
    driver: bridge

volumes:
  weaviate_data:
